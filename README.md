# Task 6 â€“ K-Nearest Neighbors (KNN) Classification

## ğŸ“Œ Overview
This task demonstrates how the KNN algorithm works for classification using the Iris dataset. The goal is to normalize features, train the model, experiment with different K values, evaluate performance, and visualize decision boundaries.

---

## ğŸ› ï¸ Tools Used
- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib
- Seaborn

---

## ğŸ§ª Steps Performed
1. Loaded the Iris dataset  
2. Normalized features using StandardScaler  
3. Split data into training & testing sets  
4. Trained a KNN model  
5. Evaluated accuracy and confusion matrix  
6. Tested multiple K values to find the best K  
7. Visualized decision boundaries  

---

## ğŸ“Š Results
- Best K value: (depends on graph result)
- Final Model Accuracy: (insert accuracy from output)

---

## â–¶ï¸ How to Run
1. Open Google Colab
2. Upload the notebook file
3. Run all cells in order

---

## ğŸ“ Project Structure

task6-knn/
â”‚
â”œâ”€â”€ Task6_KNN.ipynb

â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ¯ Conclusion
KNN works based on distance measure and performs well after normalization. Model accuracy varies depending on chosen K value, and visualization helps understand the classification boundaries.

